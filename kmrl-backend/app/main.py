
import os
import json
from math import ceil
from typing import Optional, Dict, List
from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
import google.generativeai as genai
import requests
import urllib3
from datetime import datetime, timedelta
import random

# ---------------- Suppress LibreSSL warning ----------------
urllib3.disable_warnings(urllib3.exceptions.NotOpenSSLWarning)

# ---------------- Load Environment Variables ----------------
load_dotenv("api.env")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")
WEATHER_KEY = os.getenv("WEATHER_API_KEY")
HOLIDAY_KEY = os.getenv("HOLIDAY_KEY")

KMRL_CONFIG = {
    "TOTAL_FLEET": 25,
    "TRAIN_CAPACITY": 900,
    "MAINTENANCE_RATIO": 0.1
}

genai.configure(api_key=GEMINI_KEY)

genai.configure(api_key=GEMINI_KEY)

from .staff import staff_router
from .notes import notes_router
from .reports import reports_router
from .conflicts import conflicts_router

app = FastAPI(title="KMRL AI Backend ðŸš‡")
app.include_router(staff_router)
app.include_router(notes_router)
app.include_router(reports_router)
app.include_router(conflicts_router)

from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001", "http://localhost:3002"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------- Models ----------------
class ForecastRequest(BaseModel):
    date: str
    time: str
    station: str
    passengers: int
    event: Optional[str] = None
    day_of_week: Optional[str] = None
    weather: Optional[str] = None
    holiday: Optional[bool] = False
    nearby_events: Optional[str] = None
    train_delays: Optional[int] = 0

class BatchForecastRequest(BaseModel):
    date: str
    time: str
    stations: List[str]
    weather: Optional[str] = None
    holiday: Optional[bool] = False
    day_of_week: Optional[str] = None

class PlanRequest(BaseModel):
    date: str
    station: str
    predicted_passengers: int

class ScheduleStation(BaseModel):
    station: str
    predicted_passengers: int

class ScheduleRequest(BaseModel):
    date: str
    stations: List[ScheduleStation]
    available_trains: Optional[int] = 10
    maintenance_trains: Optional[int] = 0
    staff_available: Optional[int] = 10
    peak_hours: Optional[Dict[str, float]] = None  # {"08:00-09:00":1.5}

class TrainDetail(BaseModel):
    id: str
    status: str # "Available", "Maintenance", "In Service"
    location: Optional[str] = None
    location: Optional[str] = None
    delay_minutes: int = 0
    km_run_today: float = 0.0
    ridership_load: float = 0.0 # Percentage 0-100

class FleetStatus(BaseModel):
    availability: float
    punctuality: float
    health_alerts: List[str]
    utilization: float
    total_fleet: int
    active_trains: int
    train_details: List[TrainDetail]

# --- Assignment Models ---
class TripRequest(BaseModel):
    id: str
    route_name: str
    start_time: str # HH:MM
    origin_station: str # "Aluva", "Pettah"

class AssignmentResult(BaseModel):
    trip_id: str
    train_id: str
    train_km_run: float
    is_peak_match: bool # True if Fresh Train assigned to Peak Trip
    match_reason: str

class AssignmentRequest(BaseModel):
    trips: List[TripRequest]

# ---------------- Root ----------------
@app.get("/")
def root():
    return {"message": "KMRL AI Backend Running ðŸš‡"}

# ---------------- Helper Functions ----------------
def get_weather(city="Kochi"):
    try:
        res = requests.get(
            f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={WEATHER_KEY}"
        )
        data = res.json()
        return data['weather'][0]['main']
    except:
        return "Clear"

def is_holiday(date):
    try:
        year, month, day = map(int, date.split("-"))
        res = requests.get(
            f"https://calendarific.com/api/v2/holidays?api_key={HOLIDAY_KEY}&country=IN&year={year}&month={month}&day={day}"
        )
        holidays = res.json().get('response', {}).get('holidays', [])
        return len(holidays) > 0
    except:
        return False

# ---------------- Forecast Endpoint ----------------
@app.post("/forecast")
def forecast(data: ForecastRequest):
    weather = get_weather() if not data.weather else data.weather
    holiday_flag = is_holiday(data.date) if not data.holiday else data.holiday

    model = genai.GenerativeModel("gemini-1.5-pro")
    prompt = f"""
    You are an expert metro ridership forecaster.
    Predict passenger demand using the data below.

    Date: {data.date}
    Time: {data.time}
    Station: {data.station}
    Current passengers: {data.passengers}
    Day of week: {data.day_of_week or 'Unknown'}
    Weather: {weather}
    Holiday: {holiday_flag}
    Special event: {data.event or 'None'}
    Nearby events: {data.nearby_events or 'None'}
    Previous train delays: {data.train_delays} minutes

    Respond ONLY in valid JSON:
    {{ "predicted_passengers": number }}
    """

    try:
        response = model.generate_content(prompt)
        text = response.candidates[0].content.parts[0].text.strip()
        result = json.loads(text)
        predicted = result.get("predicted_passengers", int(data.passengers * 1.2))
    except Exception as e:
        print("Gemini API failed:", e)
        multiplier = 1.0
        if data.day_of_week in ["Saturday","Sunday"]:
            multiplier *=1.2
        if holiday_flag:
            multiplier *=1.3
        if weather in ["Rain","Storm"]:
            multiplier *=0.9
        if data.nearby_events:
            multiplier *=1.15
        predicted = int(data.passengers * multiplier)

    return {
        "station": data.station,
        "date": data.date,
        "time": data.time,
        "predicted_passengers": predicted
    }

# ---------------- Batch Forecast Endpoint ----------------
@app.post("/forecast/batch")
def batch_forecast(data: BatchForecastRequest):
    weather = get_weather() if not data.weather else data.weather
    holiday_flag = is_holiday(data.date) if not data.holiday else data.holiday
    
    model = genai.GenerativeModel("gemini-1.5-pro")
    
    prompt = f"""
    You are an expert metro ridership forecaster for Kochi Metro.
    Predict daily passenger demand for the following stations.

    Context:
    Date: {data.date}
    Time: {data.time}
    Day: {data.day_of_week or 'Unknown'}
    Weather: {weather}
    Holiday: {holiday_flag}

    Station Tiers (Use this to guide prediction magnitude):
    - Tier 1 (High Traffic > 15000): Aluva, Edapally, M.G. Road, Maharaja's College, Vytila.
    - Tier 2 (Medium Traffic 8000-12000): Kalamassery, Kaloor, JLN Stadium, Palarivattom, Ernakulam South, Petta.
    - Tier 3 (Low Traffic < 5000): Pulinchodu, Companypady, Ambattukavu, Muttom, Pathadipalam, Changampuzha Park, Lissie, Kadavanthra, Elamkulam, Thykkoodam.

    Stations to Predict: {', '.join(data.stations)}

    Respond ONLY in valid JSON:
    {{
        "predictions": {{
            "Station Name": number,
            ...
        }}
    }}
    """

    try:
        response = model.generate_content(prompt)
        text = response.candidates[0].content.parts[0].text.strip()
        # Clean up potential markdown formatting
        if text.startswith("```json"):
            text = text[7:-3]
        
        result = json.loads(text)
        predictions = result.get("predictions", {})
        print(f"Batch AI Success: Received {len(predictions)} predictions")
    except Exception as e:
        print(f"Gemini Batch API failed: {e}")
        print(f"Response text was: {text if 'text' in locals() else 'None'}")
        # Fallback: Randomize slightly so graphs look different
        import random
        predictions = {st: random.randint(3000, 12000) for st in data.stations}

    # Ensure all stations have a value (fallback if AI missed one)
    final_output = []
    for st in data.stations:
        val = predictions.get(st, int(5000 * 1.1))
        final_output.append({
            "station": st,
            "predicted_passengers": val
        })

    return {
        "date": data.date,
        "time": data.time,
        "forecasts": final_output
    }

# ---------------- Mock Data Helper ----------------
def _generate_mock_fleet(total_fleet=25):
    """
    Generates a consistent mock fleet state for both Fleet Status and Assignment modules.
    Ensures trains are numbered TM-101 to TM-(100+total_fleet).
    """
    train_details = []
    
    # Trackers for summary stats (calculated by caller usually, but we need data first)
    # We just return the list of trains.
    
    now = datetime.now()
    start_of_service = now.replace(hour=6, minute=0, second=0, microsecond=0)
    current_hour = now.hour
    
    # Base Randomness Seed per hour to keep it somewhat stable between refreshes? 
    # Actually, random is fine for this demo.

    for i in range(1, total_fleet + 1):
        train_id = f"TM-{100+i}"
        delay = 0

        # Status Logic
        if i == 5:
             status = "Maintenance"
             loc = "Aluva Depot"
        elif i == 12:
             status = "Maintenance"
             loc = "Muttom Yard"
        elif i == 18:
             status = "Maintenance"
             loc = "Pettah Terminal"
        else:
             status = "In Service" if i % 2 == 0 else "Available"
             loc = f"Station {chr(65 + (i%5))}" if status == "In Service" else "Depot"
        
        # --- Metrics Calculation ---
        if status == "In Service":
            # Delays
            if random.random() < 0.15: 
                delay = random.randint(2, 12)
            
            # 1. KM Run Calculation
            if now < start_of_service:
                km_run = 0.0
            else:
                elapsed_hours = (now - start_of_service).total_seconds() / 3600
                avg_speed = 33.0 
                km_run = elapsed_hours * avg_speed
                km_run *= random.uniform(0.85, 1.15)
                km_run = round(max(0.0, km_run), 1)

            # 2. Ridership Load Calculation
            if 8 <= current_hour < 11: # Morning Peak
                base_load = random.uniform(80, 90)
            elif 17 <= current_hour < 20: # Evening Peak
                base_load = random.uniform(85, 95)
            elif 11 <= current_hour < 17: # Mid-Day
                base_load = random.uniform(40, 60)
            else: 
                base_load = random.uniform(10, 30)

            # Station Tier Multiplier
            if loc in ["Aluva", "Edapally", "M.G. Road", "Maharaja's College", "Vytila"]:
                tier_multiplier = 1.2
            elif loc in ["Kalamassery", "Kaloor", "JLN Stadium", "Palarivattom", "Ernakulam South", "Petta"]:
                tier_multiplier = 1.0
            else:
                tier_multiplier = 0.7
            
            ridership_load = base_load * tier_multiplier
            ridership_load *= random.uniform(0.9, 1.1)
            ridership_load = round(min(120.0, max(0.0, ridership_load)), 1)
            
        else:
            # "Available" or "Maintenance"
            ridership_load = 0.0
            km_run = 0.0
            
            # Simulate Morning Shift Completion for "Available" trains
            if status == "Available" and random.random() < 0.70:
                 km_run = round(random.uniform(100.0, 350.0), 1)

        train_details.append(TrainDetail(
            id=train_id, 
            status=status, 
            location=loc, 
            delay_minutes=delay,
            km_run_today=km_run,
            ridership_load=ridership_load
        ))
        
    return train_details

# ---------------- Auto-Engine Assignment Endpoint ----------------
@app.post("/assign-trains")
def assign_trains(data: AssignmentRequest):
    assignments = []
    
    # 1. Get Consistent Fleet State (TM-101 to TM-125)
    all_trains = _generate_mock_fleet(total_fleet=25)
    
    # Filter for "Available" trains only
    available_trains = [
        {"id": t.id, "km_run": t.km_run_today} 
        for t in all_trains 
        if t.status == "Available"
    ]
    
    # 2. Sort Trains: Fresher first (Lowest KM)
    available_trains.sort(key=lambda x: x['km_run'])
    
    # 3. Analyze Trips & Assign Priority
    prioritized_trips = []
    for trip in data.trips:
        hour = int(trip.start_time.split(':')[0])
        is_peak = (8 <= hour <= 10) or (17 <= hour <= 19)
        is_hub_start = trip.origin_station in ["Aluva", "Pettah", "SN Junction"]
        
        score = 0
        if is_peak: score += 2
        if is_hub_start: score += 1
        
        prioritized_trips.append({
            "trip": trip,
            "score": score,
            "is_peak": is_peak
        })
    
    # Sort trips by Score
    prioritized_trips.sort(key=lambda x: x['score'], reverse=True)
    
    # 4. Perform Matching
    used_train_ids = set()
    
    for item in prioritized_trips:
        trip = item['trip']
        score = item['score']
        
        # Find best available train
        selected_train = None
        candidates = [t for t in available_trains if t['id'] not in used_train_ids]
        
        if not candidates:
            break # No more trains!
            
        if score >= 2: # Priority Trip
            # Try to find a fresh one (< 100km used)
            fresh_candidates = [t for t in candidates if t['km_run'] < 100]
            if fresh_candidates:
                selected_train = fresh_candidates[0]
                reason = "Optimum Service: Low-mileage rake assigned to ensure reliability during peak load."
                is_optimal = True
            else:
                selected_train = candidates[0]
                reason = "Demand Coverage: Best available rake deployed to meet high passenger demand."
                is_optimal = False
        else:
            selected_train = candidates[0]
            reason = "Standard Rotation: Routine rake assignment for balanced fleet utilization."
            is_optimal = False

        if selected_train:
            used_train_ids.add(selected_train['id'])
            assignments.append(AssignmentResult(
                trip_id=trip.id,
                train_id=selected_train['id'],
                train_km_run=selected_train['km_run'],
                is_peak_match=is_optimal,
                match_reason=reason
            ))

    return assignments

# ---------------- Plan Endpoint ----------------
@app.post("/plan")
def plan_train(request: PlanRequest):
    train_capacity = KMRL_CONFIG["TRAIN_CAPACITY"]
    trains_required = ceil(request.predicted_passengers / train_capacity)
    peak_hours = ["08:00-10:00","17:00-19:00"]

    return {
        "station": request.station,
        "date": request.date,
        "trains_required": trains_required,
        "train_capacity": train_capacity,
        "peak_hours": peak_hours
    }

@app.post("/schedule")
def schedule_trains(req: ScheduleRequest):
    train_capacity = KMRL_CONFIG["TRAIN_CAPACITY"]
    schedule_result = {}

    # ---------------- Demand Profiles ----------------
    # Profile 1: Residential/Commuter (Start of line) - High Morning Outflow
    morning_peak_curve = {
        "06:00": 0.04, "07:00": 0.10, "08:00": 0.20, "09:00": 0.15,
        "10:00": 0.08, "11:00": 0.04, "12:00": 0.03, "13:00": 0.03,
        "14:00": 0.03, "15:00": 0.04, "16:00": 0.08, "17:00": 0.08,
        "18:00": 0.05, "19:00": 0.03, "20:00": 0.01, "21:00": 0.01, "22:00": 0.00
    }
    
    # Profile 2: Commercial/Office (City Center) - High Evening Outflow
    evening_peak_curve = {
        "06:00": 0.01, "07:00": 0.03, "08:00": 0.05, "09:00": 0.08,
        "10:00": 0.06, "11:00": 0.04, "12:00": 0.04, "13:00": 0.05,
        "14:00": 0.05, "15:00": 0.08, "16:00": 0.15, "17:00": 0.20,
        "18:00": 0.10, "19:00": 0.04, "20:00": 0.02, "21:00": 0.00, "22:00": 0.00
    }
    
    # Profile 3: Balanced/Mixed - Standard Dual Peak
    standard_curve = {
        "06:00": 0.02, "07:00": 0.06, "08:00": 0.12, "09:00": 0.10,
        "10:00": 0.06, "11:00": 0.05, "12:00": 0.05, "13:00": 0.05,
        "14:00": 0.05, "15:00": 0.06, "16:00": 0.10, "17:00": 0.12,
        "18:00": 0.08, "19:00": 0.05, "20:00": 0.02, "21:00": 0.01, "22:00": 0.00
    }

    # Station Type Mapping
    residential_stations = ["Aluva", "Pulinchodu", "Companypady", "Ambattukavu", "Muttom", "Kalamassery", "Petta", "Thykkoodam"]
    commercial_stations = ["M.G. Road", "Maharaja's College", "Ernakulam South", "Edapally", "Kaloor", "Lissie", "Vytila"]

    # Calculate schedule
    total_trains_deployed = 0

    for station in req.stations:
        hourly_schedule = {}
        daily_passengers = station.predicted_passengers
        station_total_trains = 0

        # Select Curve
        if station.station in residential_stations:
            curve = morning_peak_curve
        elif station.station in commercial_stations:
            curve = evening_peak_curve
        else:
            curve = standard_curve
        
        for hour_start, demand_share in curve.items():
            # Create "06:00-07:00" format key
            end_h = int(hour_start.split(':')[0]) + 1
            time_range = f"{hour_start}-{end_h:02d}:00"
            # Add randomness to curve (0.85 to 1.15)
            import random
            random_factor = random.uniform(0.85, 1.15)
            passengers = int(daily_passengers * demand_share * random_factor)
            
            # Logic: Capacity 800
            trains_needed = ceil(passengers / train_capacity)
            trains_needed = max(trains_needed, 1) # Minimum frequency
            
            hourly_schedule[time_range] = {
                "trains_assigned": trains_needed,
                "projected_load": passengers
            }
            station_total_trains += trains_needed

        schedule_result[station.station] = {
            "predicted_passengers": daily_passengers,
            "trains_assigned_total": station_total_trains,
            "hourly_schedule": hourly_schedule
        }
        total_trains_deployed += station_total_trains

    return {
        "date": req.date,
        "train_capacity": train_capacity,
        "total_trains_needed": total_trains_deployed,
        "schedule": schedule_result
    }

@app.get("/fleet", response_model=FleetStatus)
def get_fleet_status():
    total_fleet = 25 # TM-101 to TM-125
    train_details = _generate_mock_fleet(total_fleet)
    
    # Calculate aggregates
    active_trains = len([t for t in train_details if t.status == "In Service"])
    availability = round((active_trains / total_fleet) * 100, 1)
    
    delayed_trains = len([t for t in train_details if t.delay_minutes > 5])
    
    calculated_punctuality = 100.0
    if active_trains > 0:
        calculated_punctuality = ((active_trains - delayed_trains) / active_trains) * 100

    return FleetStatus(
        availability=availability,
        punctuality=round(calculated_punctuality, 1),
        health_alerts=["Train 105: HVAC degraded", "Train 112: Door sensor warning"],
        utilization=78.4,
        total_fleet=total_fleet,
        active_trains=active_trains,
        train_details=train_details
    )
